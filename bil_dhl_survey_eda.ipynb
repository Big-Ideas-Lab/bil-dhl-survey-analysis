{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import researchpy as rp\n",
    "from scipy.stats import chi2_contingency\n",
    "from statsmodels.sandbox.stats.multicomp import multipletests # for multiple comparisons correction\n",
    "from itertools import combinations  # for post-hoc tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assists in displaying significance\n",
    "# using the work from https://neuhofmo.github.io/chi-square-and-post-hoc-in-python/\n",
    "def get_asterisks_for_pval(p_val, alpha=0.05):\n",
    "    \"\"\"Receives the p-value and returns asterisks string.\"\"\"\n",
    "    if p_val > alpha:  # bigger than alpha\n",
    "        p_text = \"ns\"\n",
    "    # following the standards in biological publications\n",
    "    elif p_val < 1e-4:  \n",
    "        p_text = '****'\n",
    "    elif p_val < 1e-3:\n",
    "        p_text = '***'\n",
    "    elif p_val < 1e-2:\n",
    "        p_text = '**'\n",
    "    else:\n",
    "        p_text = '*'\n",
    "    \n",
    "    return p_text  # string of asterisks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chi-square test with multiple hypothesis correction\n",
    "# following the work from: https://neuhofmo.github.io/chi-square-and-post-hoc-in-python/\n",
    "def run_chisq_on_combination(df, combinations_tuple):\n",
    "    \"\"\"Receives a dataframe and a combinations tuple and returns p-value after performing chisq test.\"\"\"\n",
    "    assert len(combinations_tuple) == 2, \"Combinations tuple is too long! Should be of size 2.\"\n",
    "    new_df = df[(df.index == combinations_tuple[0]) | (df.index == combinations_tuple[1])]\n",
    "    # print(new_df)\n",
    "    try:\n",
    "        chi2, p, dof, ex = chi2_contingency(new_df, correction=True)\n",
    "    except ValueError:\n",
    "            print('Expected values is zero in one column for this contingency table: ')\n",
    "            print(new_df)\n",
    "            p=100 # setting some extreme values to be removed from the next list\n",
    "    return p\n",
    "\n",
    "\n",
    "def chisq_and_posthoc_corrected(df, correction_method='fdr_bh', alpha=0.05):\n",
    "    \"\"\"Receives a dataframe and performs chi2 test and then post hoc.\n",
    "    Prints the p-values and corrected p-values (after FDR correction).\n",
    "    alpha: optional threshold for rejection (default: 0.05)\n",
    "    correction_method: method used for mutiple comparisons correction. (default: 'fdr_bh').\n",
    "    See statsmodels.sandbox.stats.multicomp.multipletests for elaboration.\"\"\"\n",
    "\n",
    "    # start by running chi2 test on the matrix\n",
    "    chi2, p, dof, ex = chi2_contingency(df, correction=True)\n",
    "    print(\"Chi2 result of the contingency table: {}, p-value: {}\\n\".format(chi2, p))\n",
    "    \n",
    "    # post-hoc test\n",
    "    all_combinations = list(combinations(df.index, 2))  # gathering all combinations for post-hoc chi2\n",
    "    # print(all_combinations)\n",
    "    print(\"Post-hoc chi2 tests results:\")\n",
    "    p_vals = [run_chisq_on_combination(df, comb) for comb in all_combinations]  # a list of all p-values\n",
    "    # the list is in the same order of all_combinations\n",
    "    # print(all_combinations)\n",
    "    # print(p_vals)\n",
    "\n",
    "\n",
    "    # all_combinations = list(filter(lambda item: item > 100, my_list))\n",
    "    # check if we have any tests, where we could not run chi-square test\n",
    "    # p-value=100 (as set up in the function above)\n",
    "    # if item in p_vals == 100:\n",
    "    # print([s for s in p_vals if s != 100])\n",
    "    i=100\n",
    "    if i in p_vals:\n",
    "        print ('Invalid Chi-Square Test')\n",
    "        print('Removing that combination for post-hoc testing')\n",
    "        print(all_combinations)\n",
    "        print(p_vals)\n",
    "        del all_combinations[p_vals.index(100)]\n",
    "        p_vals=[s for s in p_vals if s != 100]\n",
    "        print('After removing that combination:')\n",
    "        print(all_combinations)\n",
    "        print(p_vals)\n",
    "\n",
    "    \n",
    "    \n",
    "    # all_combinations=all_combinations[s in p_vals if s != 100]\n",
    "\n",
    "\n",
    "    # correction for multiple testing\n",
    "    reject_list, corrected_p_vals = multipletests(p_vals, method=correction_method, alpha=alpha)[:2]\n",
    "    for p_val, corr_p_val, reject, comb in zip(p_vals, corrected_p_vals, reject_list, all_combinations):\n",
    "        print(\"{}: p_value: {:5f}; corrected: {:5f} ({}) reject: {}\".format(comb, p_val, corr_p_val, get_asterisks_for_pval(p_val, alpha), reject))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "df=pd.read_excel('smartdevice survey individual demographics and answers-deidentified.xlsx',sheet_name='XX') # Code with actual data will be uploaded later\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical Test on Ownership of Smartphone Across Demographic Factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Gender\n",
    "# Filter Dataframe to include only Male vs Female as we have very limited representation with participants from other gender types\n",
    "df_gender=df.loc[(df['Gender']=='Male') | (df['Gender']=='Female')]\n",
    "\n",
    "smartphone_ownership_gender_crosstab, smartphone_ownership_gender_test_results, smartphone_ownership_gender_expected = rp.crosstab(df_gender[\"smartphone_ownership_binary_response\"], df_gender[\"Gender\"], test= \"chi-square\", expected_freqs= True, prop= \"cell\", cramer_correction = True) \n",
    "\n",
    "\n",
    "smartphone_ownership_gender_test_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Race\n",
    "#Filter Dataframe to include only White, Black, Hispanic, and Asian as we have very limited representation from participants from race and ethnicities\n",
    "df_race=df.loc[(df['race_ethnicity']=='White or Caucasian') | (df['race_ethnicity']=='Black or African American') | (df['race_ethnicity']=='Asian or Asian American') | (df['race_ethnicity']=='Hispanic')]\n",
    "\n",
    "smartphone_ownership_race_crosstab, smartphone_ownership_race_test_results, smartphone_ownership_race_expected = rp.crosstab(df_race[\"smartphone_ownership_binary_response\"], df_race[\"race_ethnicity\"], test= \"chi-square\", expected_freqs= True, prop= \"cell\", cramer_correction = True) \n",
    "\n",
    "\n",
    "smartphone_ownership_race_test_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Age\n",
    "wearable_ownership_age_crosstab, wearable_ownership_age_test_results, wearable_ownership_age_expected = rp.crosstab(df[\"wearable_ownership_binary_response\"], df[\"generation_age_group\"], test= \"chi-square\", expected_freqs= True, prop= \"cell\", cramer_correction = True) \n",
    "\n",
    "wearable_ownership_age_test_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Chi-Square Test with Multiple Hypotheses Correction\n",
    "chisq_and_posthoc_corrected(pd.crosstab(df_age['generation_age_group'], df_age['wearable_ownership_binary_response']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Highest Level of Education \n",
    "# Filter Dataframe to exclude participants with less than high school education as we have very limited representation with people with less than high school educaiton\n",
    "df_education=df.loc[(df['Highest level of education']!='Less than high school') ]\n",
    "\n",
    "\n",
    "smartphone_ownership_education_crosstab, smartphone_ownership_education_test_results, smartphone_ownership_education_expected = rp.crosstab(df_education[\"smartphone_ownership_binary_response\"], df_education[\"Highest level of education\"], test= \"chi-square\", expected_freqs= True, prop= \"cell\", cramer_correction = True) \n",
    "\n",
    "\n",
    "smartphone_ownership_education_test_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Chi-Square Test with Multiple Hypotheses Correction\n",
    "chisq_and_posthoc_corrected(pd.crosstab(df_education[\"Highest level of education\"], df_education[\"smartphone_ownership_binary_response\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For employment status\n",
    "smartphone_ownership_employment_crosstab, smartphone_ownership_employment_test_results, smartphone_ownership_employment_expected = rp.crosstab(df[\"smartphone_ownership_binary_response\"], df[\"Employment Status\"], test= \"chi-square\", expected_freqs= True, prop= \"cell\", cramer_correction = True) \n",
    "\n",
    "smartphone_ownership_employment_test_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Chi-Square Test with Multiple Hypotheses Correction\n",
    "chisq_and_posthoc_corrected(pd.crosstab(df['Employment Status'], df['smartphone_ownership_binary_response']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure: Motivation for ownership of wearables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load data\n",
    "wearable_ownership_motivation_df=pd.read_excel('../duke_health_listens_smart_device_ownership_data.xlsx',sheet_name='Q7_wearable_device_usage_reason',index_col=0)\n",
    "#sorting DF by Main Reason\n",
    "wearable_ownership_motivation_df.sort_values(by=['Main reason'],inplace=True,ascending=True)\n",
    "\n",
    "# Generate Figure:\n",
    "list_of_colors=['tab:blue', 'tab:orange', 'tab:gray','tab:olive']\n",
    "list_of_colors=['#005587', '#0577B1','#ADD8E6','#B5B5B5']\n",
    "fig, ax = plt.subplots(1,1,figsize=(6,4))\n",
    "plt.rcParams.update({'font.size': 10, 'font.family':'sans-serif','font.sans-serif': 'Arial' })\n",
    "plt.rcParams['axes.grid'] = True\n",
    "wearable_ownership_motivation_df.plot(kind='barh', stacked=True, color=list_of_colors,ax=ax)\n",
    "\n",
    "plt.legend(ncol=2,bbox_to_anchor=(-0.3, -0.4),loc='lower left')\n",
    "ax.set_xlim(0, 100)\n",
    "ax.set_ylabel('')\n",
    "ax.set_xlabel('Motivation Priority (%)')\n",
    "\n",
    "ax.set_xticks([0, 25, 50, 75, 100])\n",
    "fig.tight_layout()\n",
    "figurename_to_save='Figures/wearable_ownership_motivation.jpg'\n",
    "plt.savefig(figurename_to_save,format='jpg', dpi = 600)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure: Willingess to share data from smartdevices for research purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load data\n",
    "data_sharing_willingness_df=pd.read_excel('../duke_health_listens_smart_device_ownership_data.xlsx',sheet_name='Q_types_of_data_comfortable_sha',index_col=0)\n",
    "data_sharing_willingness_df.sort_values(by=['Yes'],inplace=True,ascending=True)\n",
    "data_sharing_willingness_df=data_sharing_willingness_df.iloc[:,[0,2,1]] \n",
    "\n",
    "# Generate Figure:\n",
    "fig, ax = plt.subplots(1,1,figsize=(5,3))\n",
    "list_of_colors=['#005587', '#ADD8E6','#B5B5B5']\n",
    "\n",
    "plt.rcParams.update({'font.size': 10, 'font.family':'sans-serif','font.sans-serif': 'Arial' })\n",
    "\n",
    "data_sharing_willingness_df.plot(kind='barh', stacked=True, color=list_of_colors,ax=ax,zorder=3)\n",
    "\n",
    "mylabels=['Willing', 'Maybe Willing', 'Not Willing']\n",
    "plt.legend(labels=mylabels, ncol=3,bbox_to_anchor=(-0.6, -0.5),loc='lower left')\n",
    "ax.set_xlim(0, 100)\n",
    "ax.set_ylabel('Types of Data')\n",
    "ax.set_xlabel('Data Sharing Acceptability (%)')\n",
    "ax.grid(True, linestyle='--',axis='x',zorder=0)\n",
    "ax.set_xticks([0, 25, 50, 75, 100])\n",
    "fig.tight_layout()\n",
    "figurename_to_save='Figures/data_sharing_willingness.jpg'\n",
    "plt.savefig(figurename_to_save,format='jpg', dpi = 600)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
